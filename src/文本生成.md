# 文本生成

<!-- toc -->

## 文本生成概述

什么是自然语言生成？

自然语言生成是为了达到特定交流目标而生成自然语言文本的过程

根据给定的需求和规则组织组织信息、生成语法正确且通顺的文本

文本生成任务是自然语言生成的应用

常见任务：文本摘要、机器翻译、文本描述、对话生成

## 文本生成方法


### 基于规则的文本生成

代码模板，if-else字符串填充

优点：速度快，无需复杂的计算；输出结果高度可确定

缺点：泛化性差，输出缺乏多样性

### 基于统计机器学习的文本生成

常见的有朴素贝叶斯算法、N-gram

通过统计语料库总督词语和短语的频率，预测下一个词或短语出现的概率

用于语音识别、搜索引擎、输入法等实时性要求比较高的场景

缺点：处理长文本时具有较大的局限性
### 基于深度学习的文本生成

常见工具：

- RNN、LSTM
- BART、GPT、T5

基于语言模型生成文本

训练一个语言模型表示语言的潜在空间即统计结构
- 输入前面的标记，语言模型能够预测序列中后续的一个或多个标记
- 标记通常是单词或字符

使用训练好的语言模型生成新序列
## 文本序列生成模型BART

BART：Bidirectional and Auto-Regressive Transformers

BART通过Transformers中的Encoder-Decoder架构生成文本

### 采样策略

生成文本时如何选取下一个token

常用策略：

- 贪婪采样：每次选择最优，复杂度低，无法保证全局最优
- 随机采样：获得下一个Token的概率分布后，利用温度、top-k（取词表打分最高的前K个词）、top-p（概率之和不超过p）等算法对概率进行修改，再进行随机采样，常用于开放式对话领域提高生成文本的多样性，适合较短的文本。缺点：随机采样容易产生文本语义、逻辑等前后不一致的问题
- 束搜索Beam Search：同时生成多句话，取整体概率最优解。能够生成高质量、连贯性强的文本，常用于机器翻译、文本摘要和对话系统


## 可控文本生成CTG

可控文本生成和传统自然语言生成的区别：在输入时加入某些控制元素，从而让最终的输出满足满足某种条件

例如：安装故事线给定关键字生成文章

要求：生成文章涵盖关键字，关键字按照顺序出现且逻辑通顺

### 可控文本生成方法

- 微调
- 重构
- 后处理
